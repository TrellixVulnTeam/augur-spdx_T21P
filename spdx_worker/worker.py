import logging, os, sys, time, requests, json
from datetime import datetime
from multiprocessing import Process, Queue
import pandas as pd
import sqlalchemy as s
from workers.worker_base import Worker
import subprocess
import psycopg2
from subprocess import PIPE
import json
import re
import os
import requests
from os.path import expanduser

#import sbom_populate as p
#import initial_scans as s

class TemplateWorker(Worker):

    def __init__(self, config):
        # Define what this worker can be given and know how to interpret

        # given is usually either [['github_url']] or [['git_url']] (depending if your 
        #   worker is exclusive to repos that are on the GitHub platform)
        given = [['git_url']]

        # The name the housekeeper/broker use to distinguish the data model this worker can fill
        #   You will also need to name the method that does the collection for this model
        #   in the format *model name*_model() such as fake_data_model() for example
        models = ['spdx']

        # Define the tables needed to insert, update, or delete on
        #   The Worker class will set each table you define here as an attribute
        #   so you can reference all of them like self.message_table or self.repo_table
        data_tables = ['message', 'repo']
        # For most workers you will only need the worker_history and worker_job tables
        #   from the operations schema, these tables are to log worker task histories
        operations_tables = ['worker_history', 'worker_job']

        # Run the general worker initialization
        super().__init__(config, given, models, data_tables, operations_tables)

        # Define data collection info
        self.tool_source = 'SPDX Worker'
        self.tool_version = '0.9.0'
        self.data_source = 'SPDX License Scans'

    def spdx_model(self, task, repo_id):
        """ This is just an example of a data collection method. All data collection 
            methods for all workers currently accept this format of parameters. If you 
            want to change these parameters, you can re-define the collect() method to 
            overwrite the Worker class' version of it (which is the method that calls
            this method).

            :param task: the task generated by the housekeeper and sent to the broker which 
            was then sent to this worker. Takes the example dict format of:
                {
                    'job_type': 'MAINTAIN', 
                    'models': ['fake_data'], 
                    'display_name': 'fake_data model for url: https://github.com/vmware/vivace',
                    'given': {
                        'git_url': 'https://github.com/vmware/vivace'
                    }
                }
            :param repo_id: the collect() method queries the repo_id given the git/github url
            and passes it along to make things easier. An int such as: 27869
        """
        with open("../../augur.config.json") as json_file:
        config = json.load(json_file)
        dbname = config["Database"]["database"]
        user = config["Database"]["user"]
        password = config["Database"]["password"]
        host = config["Database"]["host"]
        port = config["Database"]["port"]
        dsfile = config["Workers"]["license_worker"]["tagfile"]
        depth = config["Workers"]["license_worker"]["search_depth"]
        ipath = config["Workers"]["facade_worker"]["repo_directory"]
        home = expanduser("~")

        configtools = 'postgresql://{}:{}@{}:{}/{}'.format(
            user, password, host, port, dbname
        )

        with open("dosocs2-example.conf") as configfile:
            content = configfile.read()
            content_new = re.sub('(connection_uri = .*)\n', "connection_uri = " + configtools + "?options=--search_path=spdx\n", content)
            with open("dosocs2.conf","w+") as outfile:
                outfile.write(content_new)
            with open(home + "/.config/dosocs2/dosocs2.conf","w+") as coreconfig:
                coreconfig.write(content_new)

        wd = os.getcwd()

        def depthwalk(ipath, depth, match):
           k = 0
           #print("IPATH " + ipath)
           if depth > 0:
             for dir in os.listdir(ipath):
               if not ipath.endswith("/"):
                   usedir = ipath + "/" + dir
               else:
                   usedir = ipath + dir
               if os.path.isdir(usedir):
                   if dir == match:
                      print("FOLDER FOUND: " + str(usedir))
                      pathtot.append(usedir)
                      break
                   depthwalk(usedir, depth - 1, match)

        def initscan(dbname, user, password, host, port, dsfile, ipath, depth):
            connection = psycopg2.connect(
                user = user,
                password = password,
                database = dbname,
                host = host,
                port = port,
            )
            print("********************")
            cur = connection.cursor()
            r = cur.execute("set search_path to augur_data; select repo_path, repo_id, repo_group_id, repo_name from repo order by repo_group_id;")
            rec = cur.fetchall()
            for sector in rec:
                global pathtot
                pathtot = []
                print(sector)
                repo_id = sector[1]
                print("****************")
                print(repo_id)
                cur.execute("set search_path to spdx;")
                cur.execute("select sbom_scan from augur_data.repo_sbom_scans where repo_id = " + str(repo_id) + " LIMIT 1;")
                determin = cur.fetchall()
                if not determin:
                    cur.execute("select dosocs_pkg_id from spdx.augur_repo_map where repo_id = " + str(repo_id) + " LIMIT 1;")
                    records = cur.fetchall()
                    print("****************")
                    print(str(sector[0]))
                    if not ipath.endswith("/"):
                        ipath = ipath + "/"
                    #path = ipath + str(sector[3])
                    os.chdir(ipath)
                    print("---------------")
                    #need to make this a config parameter
                    depthwalk(ipath, depth, sector[3])
                    time.sleep(0.2)
                    print("INSIDE: "  + str(pathtot))
                    print("---------------")
                    if pathtot != []:
                        path = pathtot[0]
                        print("PATH: " + str(path))
                        print("SELECT repo_path FROM spdx.augur_repo_map WHERE " + chr(39) + path + chr(39) + " " + chr(61) + " repo_path;")
                        cur.execute("SELECT repo_path FROM spdx.augur_repo_map WHERE " + chr(39) + path + chr(39) + " " + chr(61) + " repo_path;")
                        if str(len(cur.fetchall())) == "0":
                            print("ALL CHECKS PASSED")                                                                                                                                                                                                                                                                #Create a new record in "packages" table.                                                                                                                                                                                                                                                 #dosocs will determine whether the entry has already been made
                            print("Creating Record for " + str(sector[1]))
                            #cur.execute("INSERT INTO spdx.augur_repo_map(repo_id, repo_path) VALUES (" + str(sector[1]) + "," + chr(39) + str(sector[0]) + str(sector[3]) + chr(39) + ");")
                            cur.execute("INSERT INTO spdx.augur_repo_map(repo_id, repo_path) VALUES (" + str(sector[1]) + "," + chr(39) + path + chr(39) + ");")
                            connection.commit()
                            #Attempt to create new DoSOCS entry
                            print("CREATING NEW DOSOCS DOCUMENT")
                            print(path)
                            p = subprocess.Popen(['dosocs2', 'scan', str(path)], shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                            print(str(p.communicate()))
                            (output) = p
                            print("####################")
                            print(output)
                            print("RECORD CREATED")
                        else:
                            print("RECORD EXISTS IN MAP TABLE")
                    else:
                        print("NO DIRECTORY, SKIPPING")
                else:
                    print("DUPLICATE RECORD FOUND IN REPO_SBOM_SCANS. SKIPPING...")
            cur.execute("update augur_repo_map a set dosocs_pkg_name = b.name from packages b where a.repo_path = b.download_location;")
            cur.execute("update augur_repo_map a set dosocs_pkg_id = b.package_id from packages b where a.repo_path = b.download_location;")
            connection.commit()
            cur.close()
            connection.close()
            return

        def parse_json(doc_1, cre_1, pac_1, pac_lif_1, pac_2, fil_dat_1, fil_rel_1, bas_rel_1, cov_1, cur, repo_id):
            license_information = {}
            temp_1 = {}
            for i in range(0, int(len(doc_1[0])/2)):
                j = i*2
                temp_1[doc_1[0][j]] = doc_1[0][j+1]

            doc_1_temp = {**temp_1}

            temp_1 = {}
            for i in range(0, int(len(cre_1[0])/2)):
                j = i*2
                temp_1[cre_1[0][j]] = cre_1[0][j+1]

            cre_1_temp = {**temp_1}

            temp_1 = {}
            for i in range(0, int(len(pac_1[0])/2)):
                j = i*2
                temp_1[pac_1[0][j]] = pac_1[0][j+1]
            temp_2 = {}
            for i in range(0, int(len(pac_lif_1[0])/2)):
                j = i*2
                temp_2[pac_lif_1[0][j]] = pac_lif_1[0][j+1]
            temp_3 = {}
            for i in range(0, int(len(pac_2[0])/2)):
                j = i*2
                temp_3[pac_2[0][j]] = pac_2[0][j+1]

            pac_temp = {**temp_1, **temp_2, **temp_3}

            temp_2 = {}
            for g in range(0, int(len(fil_dat_1))):
                temp_1 = {}
                for i in range(0, int(len(fil_dat_1[g])/2)):
                    j = i*2
                    temp_1[fil_dat_1[g][j]] = fil_dat_1[g][j+1]
                temp_1['File Relationship'] = fil_rel_1[g][2].split(": ")[1]
                temp_2["File " + str(g)] = temp_1
            fil_temp = {**temp_2}

            temp_2 = {}
            for k in range(0, int(len(bas_rel_1))):
                temp_2["Relationship " + str(k)] = bas_rel_1[k][1]
            bas_rel_temp = {**temp_2}

            temp_1 = {}
            for i in range(0, int(len(cov_1[0])/2)):
                j = i*2
                temp_1[cov_1[0][j]] = cov_1[0][j+1]

            cov_temp = {**temp_1}

            license_information['Document Information'] = doc_1_temp
            license_information['Creation Information'] = cre_1_temp
            license_information['Package Information'] = pac_temp
            license_information['File Information'] = fil_temp
            license_information['Package Relationships'] = bas_rel_temp
            license_information['License Coverage'] = cov_temp

            cur.execute("insert into augur_data.repo_sbom_scans(repo_id, sbom_scan) VALUES(" + str(repo_id)  + "," +  chr(39) + str(json.dumps(license_information)).replace("'", "") + chr(39) + ");")

        def grabreg(records, repo_id, dsfile):
            print("DETAILS FOUND. CREATING DOCUMENT")
            proc = subprocess.Popen("dosocs2 generate " + str(records[0][0]), shell=True, stdout=PIPE, stderr=PIPE)
            varerr = str(str(proc.stderr.read()).split(" ")[3])
            charvarerr = varerr.split("\\")[0]
            print("Document_id: " + str(charvarerr))
            #f = open("/home/sean/dosocs2/accessDB/scans-tv/" + repo_name + "-full.txt","w")
            #proc = subprocess.call("dosocs2 print " + str(charvarerr) + " -T 2.0.tag.coverage", shell=True, stdout=f, stderr=f)
            pope = subprocess.Popen("dosocs2 print " + str(charvarerr) + " -T " + dsfile, shell=True, stdout=PIPE, stderr=PIPE)
            out, err = pope.communicate()
            #if out:                                                                                                                                                                                                                                                                                      #with open('ex-raw.txt', 'w+') as example:
                #    example.write(out.decode('UTF-8'))
            if err:                                                                                                                                                                                                                                                                                       print(err.decode('UTF-8'))
            #print (out)                                                                                                                                                                                                                                                                              #package_sr_1 = re.findall(r'(PackageName): (.*)\n(SPDXID): (.*)\n(PackageVersion|)? ?(.*|)\n?(PackageFileName): (.*)\n(PackageSupplier): (.*)\n(PackageOriginator): (.*)\n(PackageDownloadLocation): (.*)\n(PackageVerificationCode):? ?(.*|)\n?(PackageHomePage): (.*)\n(PackageLic>    doc_1 = re.findall(r'(DataLicense): (.*)\n(SPDXID): (.*)\n(DocumentNamespace): (.*)\n(DocumentName): (.*)\n(DocumentComment|): ?(.*|)\n?(LicenseListVersion):(.*)', out.decode('UTF-8'))
            cre_1 = re.findall(r'(Creator): (.*)\n(Created): (.*)\n(CreatorComment|): ?(.*|)', out.decode('UTF-8'))
            pac_1 = re.findall(r'(PackageName): (.*)\n(SPDXID): (.*)\n(PackageFileName): (.*)\n(PackageDownloadLocation): (.*)\n(PackageVerificationCode): (.*)\n(PackageHomePage): (.*)\n(PackageLicenseConcluded): (.*)\n(PackageLicenseDeclared): (.*)', out.decode('UTF-8'))
            pac_lif_1 = re.findall(r'(PackageLicenseInfoFromFiles): (.*)', out.decode('UTF-8'))
            pac_2 = re.findall(r'(PackageCopyrightText): (.*)', out.decode('UTF-8'))
            fil_dat_1 = re.findall(r'(FileName): (.*)\n(SPDXID): (.*)\n(FileType): (.*)\n(FileChecksum): (.*)\n(LicenseConcluded): (.*)\n(LicenseInfoInFile): (.*)\n(LicenseComments|): ?(.*|)\n(FileCopyrightText): (.*)\n(FileComment|): ?(.*|)\n(FileNotice|): ?(.*|)\n', out.decode('UTF-8'))
            fil_rel_1 = re.findall(r'(## Relationships)\n((\w.*)\n)*', out.decode('UTF-8'))
            bas_rel_1 = re.findall(r'## --------------- Relationship ---------------\n(Relationship): (.*?)\n', out.decode('UTF-8'))
            cov_1 = re.findall(r'(TotalFiles): (.*)\n(DeclaredLicenseFiles): (.*)\n(PercentTotalLicenseCoverage): (.*)\n', out.decode('UTF-8'))
            return (doc_1, cre_1, pac_1, pac_lif_1, pac_2, fil_dat_1, fil_rel_1, bas_rel_1, cov_1)

        def docscan(dbname, user, password, host, port, dsfile, ipath):
            connection = psycopg2.connect(
                user = user,
                password = password,
                database = dbname,
                host = host,
                port = port,
            )
            print("********************")
            cur = connection.cursor()
            r = cur.execute("set search_path to augur_data; select repo_path, repo_id, repo_group_id, repo_name from repo order by repo_group_id;")
            rec = cur.fetchall()
            for sector in rec:
                print(sector)
                repo_id = sector[1]
                print("****************")
                print(repo_id)
                cur.execute("set search_path to spdx;")
                cur.execute("select sbom_scan from augur_data.repo_sbom_scans where repo_id = " + str(repo_id) + " LIMIT 1;")
                determin = cur.fetchall()
                if not determin:
                    cur.execute("select dosocs_pkg_id from spdx.augur_repo_map where repo_id = " + str(repo_id) + " LIMIT 1;")
                    records = cur.fetchall()
                    print("****************")
                    if records and records[0][0] != None:
                        (doc_1, cre_1, pac_1, pac_lif_1, pac_2, fil_dat_1, fil_rel_1, bas_rel_1, cov_1) = grabreg(records, repo_id, dsfile)
                        parse_json(doc_1, cre_1, pac_1, pac_lif_1, pac_2, fil_dat_1, fil_rel_1, bas_rel_1, cov_1, cur, repo_id)
                        connection.commit()
                    else:
                        print("ERROR: RECORD DOES NOT EXIST IN MAPPING TABLE")
                else:
                    print("DUPLICATE RECORD FOUND. SKIPPING")
            return

        print("---------------------")
        print("INITIAL SCANS RUNNING")
        print("---------------------")
        initscan(dbname, user, password, host, port, dsfile, ipath, depth)
        #print(os.getcwd())
        os.chdir(wd)
        #print(os.getcwd())
        print("------------------")
        print("SBOM SCANS RUNNING")
        print("------------------")
        docscan(dbname, user, password, host, port, dsfile, ipath)
        # Collection and insertion of data happens here

        # ...

        # Register this task as completed.
        #   This is a method of the worker class that is required to be called upon completion
        #   of any data collection model, this lets the broker know that this worker is ready
        #   for another task
        self.register_task_completion(task, repo_id, 'spdx')

